# Task 2 --- Team-Mars

Thank you Team-Mars for you work!

Feedback
1. Good
    1. Introduce the task.
    2. The breakdown and experiment steps are clear. 
    3. Discussions regarding the results. 
2. Other comments
    1. Improper data were used to train and test your model. Training and testing the model on the same AE variants will lead to the overfitting on such samples. When building a defense, we are facing an open-ended problem, in which the attacker can generate an AE using any attack with any possible adversarial configurations. It will be very expensive to presume so many AE variants during training. You did not feel the pain because we provided the AEs for you. If you generate these AEs by yourself and during the training, you might quite due to the computational cost (time and space). Besides, it can result in a model that overfit on the attacks used during training and is still vulnerable against other attacks. So, a more reasonable experiment setting is to train the model on (1) the clean data (a.k.a. legitimate data, benign samples) or (2) the clean data plus data generated by an attack optimizer (refer to ``PGD-ADT``). Ideally, you train the model using the clean training data (``60k`` in total) from the dataset (Frameworks like ``Tensorflow``, ``PyTorch``, and ``Keras`` provide APIs to download the clean training/test data automatically). Consider the time issue, in this task, you can split the clean test data (in total ``10k``) in to training and validation data (typically ``0.8:0.2``).
    2. If I understood you correctly, you merged all AE variants (split data) into one big test set. This does not provide any insights, the important information of the AEs were lost. The parameters of an attack somehow indicates the strength of the generated AEs, e.g., with a larger ![\epsilon](https://latex.codecogs.com/svg.latex?\epsilon), ``FGSM`` generates stronger AEs.  Moreover, the effectiveness of a defense may vary among different attacks. A defense that is effective against one attack (or the mixed AEs) does not infer that the effectiveness against another attack.
    3. Some files used in your task 2 assignment were not submitted. For example, the ``sample/`` folder and files in it were not found on your repo.
    4. It is better to leave the scripts in a separate file(s). List the paths (locations) to all relevant files to this task, such as the json files for configurations, the python files (or Jupyter notebooks) for scripts (implemented or modified by you), files for results, location for generated AEs, etc.  
